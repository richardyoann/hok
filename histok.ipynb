{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta, date\n",
    "import sqlalchemy\n",
    "import logging.handlers\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import argparse\n",
    "from typing import List, Optional, Dict, Union, Tuple\n",
    "from IPython import get_ipython\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import gc\n",
    "import json\n",
    "from enum import Enum, auto\n",
    "\n",
    "def charger_config(fichier_config: str) -> dict:\n",
    "    try:\n",
    "        with open(fichier_config, 'r', encoding='utf-8') as fichier:\n",
    "            contenu = fichier.read()            \n",
    "            return json.loads(contenu)        \n",
    "    except json.JSONDecodeError as e:\n",
    "        logger_info.error(f\"Erreur de décodage JSON dans le fichier de configuration : {str(e)}\")\n",
    "        raise\n",
    "    except FileNotFoundError:\n",
    "        logger_info.error(f\"Le fichier de configuration '{fichier_config}' n'a pas été trouvé\")\n",
    "        raise\n",
    "    except PermissionError:\n",
    "        logger_info.error(f\"Permissions insuffisantes pour lire le fichier de configuration '{fichier_config}'\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger_info.error(f\"Erreur inattendue lors de la lecture du fichier de configuration : {str(e)}\")\n",
    "        raise    \n",
    "########################################\n",
    "# Constantes d'environnement à adapter\n",
    "########################################\n",
    "\n",
    "LOGLEVEL: int = logging.INFO\n",
    "\n",
    "# Chargement du fichier de configuration\n",
    "config = charger_config('config.json')\n",
    "\n",
    "# Chemins des fichiers et logs\n",
    "SQLPATH: Path = Path(config['paths']['sql_path'])\n",
    "LOGPATH: Path = Path(config['paths']['log_path'])\n",
    "LOGFILE: Path = Path(config['paths']['name_log_path'])\n",
    "    \n",
    "# Chemin odbc.ini\n",
    "ODBC_INI: Path = Path('../.odbc.ini')  \n",
    "\n",
    "# Chaînes de connexion ODBC\n",
    "ODBC_STRING_R: str = \"DTA_lecture\"\n",
    "ODBC_STRING_W: str = \"DTA_lecture\"\n",
    "\n",
    "# Structure des tables de la BDD prod\n",
    "SCHEMA: str = config['connexion']['schema_preprod']\n",
    "\n",
    "SQL_MOIS: str = 'indic_mois_kpi'\n",
    "\n",
    "# Colonnes attendues dans le résultat des requêtes SQL\n",
    "SQL_FORMAT_LABELS: List[str] = config['module']['sql_format_labels']\n",
    "\n",
    "# Fichiers flag pour ne pas recalculer les données journalières et mensuelles\n",
    "FLAG_FILE_DAILY: Path = Path(config['paths']['flag_file_daily'])\n",
    "FLAG_FILE_MONTHLY: Path = Path(config['paths']['flag_file_monthly'])\n",
    "\n",
    "########################################\n",
    "# Configuration du logger\n",
    "########################################\n",
    "\n",
    "logging.basicConfig() \n",
    "formatter_info = logging.Formatter(config['logging']['formatters']['default']['format'])\n",
    "\n",
    "logger_info = logging.getLogger(\"hok\")\n",
    "fh = logging.handlers.TimedRotatingFileHandler(LOGPATH / LOGFILE\n",
    "                                               , config['logging']['handlers']['file']['when']\n",
    "                                               , config['logging']['handlers']['file']['interval']\n",
    "                                               , config['logging']['handlers']['file']['backupCount'])\n",
    "\n",
    "logger_info.setLevel(LOGLEVEL)\n",
    "fh.setFormatter(formatter_info)\n",
    "logger_info.addHandler(fh)\n",
    "\n",
    "########################################\n",
    "# Décorateur \n",
    "########################################\n",
    "def log_execution_time(func):\n",
    "    \"\"\"Récupère le temps d'execution d'un traitement.\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        logger_info.info(f\"Exécution de {func.__name__} terminée en {execution_time:.2f} secondes\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Fonction permettant la gestion des données avec df\n",
    "# Une fois le traitement terminé, df sera automatiquement supprimé\n",
    "@contextmanager\n",
    "def manage_dataframe(df: pd.DataFrame):\n",
    "    try:\n",
    "        yield df\n",
    "    finally:\n",
    "        del df\n",
    "        gc.collect()\n",
    "        \n",
    "########################################\n",
    "# Classes\n",
    "########################################\n",
    "\n",
    "class HistorisationError:\n",
    "    def __init__(self):\n",
    "        self.error_messages: List[str] = []\n",
    "        self.total_exitcode: int = 0\n",
    "\n",
    "    def add_error(self, message: str) -> None:\n",
    "        self.error_messages.append(message)\n",
    "        self.total_exitcode += 1\n",
    "\n",
    "    def get_summary(self) -> Tuple[List[str], int]:        \n",
    "        return self.error_messages, self.total_exitcode\n",
    "\n",
    "    def get_str(self) -> str:        \n",
    "        return f\"Nombre total d'erreurs : {self.total_exitcode}\\nMessages d'erreur :\\n\" + \\\n",
    "               \"\\n\".join(f\"- {msg}\" for msg in self.error_messages)\n",
    "        \n",
    "class Connection_DB:\n",
    "    def __init__(self, user: str, password: str, host: str, port: int, bdd: str, historization_error: HistorisationError ):\n",
    "        try:           \n",
    "            # Utilisez les arguments s'ils sont fournis, sinon utilisez les valeurs par défaut           \n",
    "            self.user =  user \n",
    "            self.password =  password\n",
    "            self.host =  host \n",
    "            self.port =  port \n",
    "            self.bdd =  bdd   \n",
    "            self.historization_error = historization_error        \n",
    "            self.connection_string = f'postgresql://{self.user}:{self.password}@{self.host}:{self.port}/{self.bdd}'    \n",
    "            self.engine = sqlalchemy.create_engine(self.connection_string)\n",
    "            self.connection : Optional[sqlalchemy.engine.base.Connection] = None\n",
    "            logger_info.info(f\"Initialisation réussie de Connection_DB\")            \n",
    "        except Exception as e:            \n",
    "            error_msg =f\"Erreur lors de la connexion : {str(e)}\"\n",
    "            logger_info.error(error_msg)            \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "            \n",
    "    def connect(self)-> sqlalchemy.engine.base.Connection:\n",
    "        \"\"\"Établit une connexion à la base de données.\"\"\"\n",
    "        try:\n",
    "            if not self.connection or self.connection.closed:\n",
    "                self.connection = self.engine.connect()\n",
    "            return self.connection\n",
    "        except Exception as e:\n",
    "            error_msg =f\"Erreur lors de la connexion avec la bdd : {str(e)}. Le script s'arrete.\"\n",
    "            logger_info.error(error_msg)                       \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "            SystemExit(self.historization_error.get_str())\n",
    "            \n",
    "                \n",
    "    def disconnect(self)-> None:\n",
    "        \"\"\"Ferme la connexion à la base de données.\"\"\"\n",
    "        try:\n",
    "            if self.connection and not self.connection.closed:\n",
    "                self.connection.close()\n",
    "            self.engine.dispose()\n",
    "            logger_info.info(f\"Connexion fermée avec succès\")\n",
    "        except Exception as e:\n",
    "            error_msg =f\"Erreur lors de la déconnexion avec la bdd : {str(e)}\"\n",
    "            logger_info.error(error_msg)                       \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "\n",
    "class DatabaseAccess:\n",
    "    \"\"\"Classe pour accéder et manipuler la base de données.\"\"\"\n",
    "    def __init__(self, historization_error: HistorisationError, user: str, password: str, host: str, port: int, bdd: str ):  \n",
    "        self.historization_error = historization_error\n",
    "        self.read = Connection_DB(user, password, host, port, bdd, self.historization_error)\n",
    "        self.write = Connection_DB(user, password, host, port, bdd, self.historization_error)\n",
    "        \n",
    "    def disconnect(self) -> None:\n",
    "        \"\"\"Ferme toutes les connexions à la base de données.\"\"\"\n",
    "        self.read.disconnect()\n",
    "        self.write.disconnect()\n",
    "        \n",
    "    @log_execution_time\n",
    "    def read_sql_query(self, sql) -> pd.DataFrame:\n",
    "        \"\"\"Exécute une requête SQL en lecture.\"\"\"       \n",
    "        try:            \n",
    "            query = sqlalchemy.text(sql)\n",
    "            with self.read.connect() as conn:                \n",
    "                return pd.read_sql(query, conn)\n",
    "        except Exception as e:\n",
    "            error_msg =f\"Erreur lors de l'exécution de la requête SQL en lecture : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "            \n",
    "    @log_execution_time\n",
    "    def execute_query(self, sql: str):# -> Result:\n",
    "        \"\"\"Exécute une requête SQL en écriture.\"\"\"\n",
    "        try:   \n",
    "            with self.write.connect() as conn:\n",
    "                return conn.execute(sql)\n",
    "        except Exception as e:\n",
    "            error_msg =f\"Erreur lors de l'exécution de la requête SQL en écriture : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "            \n",
    "    @log_execution_time        \n",
    "    def read_sql_query_file(self, sqlfilename : Path) -> pd.DataFrame:\n",
    "        \"\"\"Lit et exécute une requête SQL depuis un fichier.\"\"\"\n",
    "        try: \n",
    "            with sqlfilename.open('r', encoding='utf-8') as fd:\n",
    "                requete = fd.read()\n",
    "            if not isinstance(requete, str):\n",
    "                raise ValueError(f\"Le contenu du fichier {sqlfilename} n'est pas une chaîne de caractères valide.\")           \n",
    "            return self.read_sql_query(requete)   \n",
    "        except Exception as e:\n",
    "            error_msg =f\"Erreur lors de la lecture et exécution du fichier SQL {sqlfilename}: {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "\n",
    "    @log_execution_time        \n",
    "    def insert_dataframe(self, df_out: pd.DataFrame, table: str, if_exists: str = 'append') -> None:        \n",
    "        \"\"\"Insère un DataFrame dans une table de la base de données.\"\"\"\n",
    "        try:\n",
    "            df_out.to_sql(table, self.write.engine, schema=SCHEMA, index=False, if_exists=if_exists)\n",
    "            logger_info.info(f\"Insertion réussie de {len(df_out)} lignes dans {SCHEMA}.{table}\")\n",
    "        except Exception as e:           \n",
    "            error_msg =f\"Erreur lors de l'insertion d'un DataFrame dans {SCHEMA}.{table} : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "\n",
    "    @log_execution_time        \n",
    "    def delete_day_data(self, date: Union[str, datetime, date]) -> None:\n",
    "        \"\"\"Supprime les données d'un jour spécifique.\"\"\"\n",
    "        try:\n",
    "            query = f\"DELETE FROM {SCHEMA}.{Tables.JOURS} WHERE date = '{date}'\"\n",
    "            self.execute_query(query)\n",
    "            logger_info.info(f\"Données du {date} supprimées de la table {Tables.JOURS}\")\n",
    "        except Exception as e:            \n",
    "            error_msg =f\"Erreur lors de la suppression des données du jour : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "\n",
    "    @log_execution_time        \n",
    "    def delete_month_data(self, year: int, month: int) -> None:\n",
    "        \"\"\"Supprime les données d'un mois spécifique.\"\"\"\n",
    "        try:\n",
    "            query = f\"DELETE FROM {SCHEMA}.{Tables.MOIS} WHERE EXTRACT(YEAR FROM date) = {year} AND EXTRACT(MONTH FROM date) = {month}\"\n",
    "            self.execute_query(query)\n",
    "            logger_info.info(f\"Données du mois {month}/{year} supprimées de la table {Tables.MOIS}\")            \n",
    "        except Exception as e:\n",
    "            error_msg =f\"Erreur lors de la suppression des données du mois : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "            \n",
    "    @log_execution_time\n",
    "    def delete_yesterday_data(self) -> None:\n",
    "        \"\"\"Supprime les données de la veille.\"\"\"\n",
    "        yesterday = (datetime.now() - timedelta(days=1)).date()\n",
    "        self.delete_day_data(yesterday)\n",
    "        \n",
    "class FlagType(Enum):\n",
    "    DAILY = \"day\"\n",
    "    MONTHLY = \"month\"\n",
    "\n",
    "class FlagAction(Enum):\n",
    "    CHECK = \"check\"\n",
    "    CREATE = \"create\"\n",
    "    REMOVE = \"remove\"   \n",
    "    \n",
    "class FlagManager:\n",
    "    \"\"\"Gère les flags pour l'historisation des KPI\"\"\"\n",
    "    def __init__(self,historization_error: HistorisationError):        \n",
    "        self.historization_error = historization_error\n",
    "\n",
    "    def manage_flag(self, flag_path: Path, action: FlagAction, flag_type: FlagType = FlagType.DAILY) -> bool:\n",
    "        \"\"\"Gère les opérations sur les flags (vérification, création, suppression)\"\"\"\n",
    "        try:\n",
    "            flag_file = flag_path.with_suffix('.flag')\n",
    "            \n",
    "            if action == FlagAction.CHECK:\n",
    "                return self._check_flag(flag_file, flag_type)\n",
    "            elif action == FlagAction.CREATE:\n",
    "                return self._create_flag(flag_file)\n",
    "            elif action == FlagAction.REMOVE:\n",
    "                return self._remove_flag(flag_file)            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Erreur lors de l'action {action.value} sur le flag {flag_path}: {str(e)}\"\n",
    "            logger_info.error(error_msg)\n",
    "            self.historization_error.add_error(error_msg)\n",
    "            return False\n",
    "        \n",
    "    def _check_flag(self, flag_file: Path, flag_type: FlagType) -> bool:\n",
    "        \"\"\"Vérifie l'existence et la validité du flag\"\"\"\n",
    "        logger_info.info(f\"Vérification de l'existence du flag : {flag_file}\")\n",
    "        \n",
    "        if not flag_file.exists():\n",
    "            return False\n",
    "\n",
    "        with open(flag_file, 'r', encoding='utf-8') as f:\n",
    "            flag_date = date.fromisoformat(f.read().strip())\n",
    "        \n",
    "        today = date.today()\n",
    "        \n",
    "        if flag_type == FlagType.MONTHLY:\n",
    "            return flag_date.replace(day=1) == today.replace(day=1)\n",
    "        return flag_date == today\n",
    "\n",
    "    def _create_flag(self, flag_file: Path) -> bool:\n",
    "        \"\"\"Crée le flag avec la date du jour\"\"\"\n",
    "        with open(flag_file, 'w') as f:\n",
    "            f.write(date.today().isoformat())\n",
    "        logger_info.info(f\"Flag créé : {flag_file}\")\n",
    "        return True\n",
    "\n",
    "    def _remove_flag(self, flag_file: Path) -> bool:\n",
    "        \"\"\"Supprime le flag s'il existe\"\"\"\n",
    "        if flag_file.exists():\n",
    "            flag_file.unlink()\n",
    "            logger_info.info(f\"Flag supprimé : {flag_file}\")\n",
    "        return True\n",
    "        \n",
    "class BaseTable:\n",
    "    \"\"\"Classe de base pour les opérations sur les tables.\"\"\"\n",
    "    def __init__(self, table_name: str, db_connection: DatabaseAccess, historization_error: HistorisationError):\n",
    "        self.schema = SCHEMA\n",
    "        self.table_name = table_name\n",
    "        self.db_connection = db_connection\n",
    "        self.historization_error = historization_error\n",
    "        \n",
    "    def get_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Récupère toutes les données de la table.\"\"\"\n",
    "        query = f\"SELECT * FROM {self.schema}.{self.table_name}\"\n",
    "        return self.db_connection.read_sql_query(query)     \n",
    "    \n",
    "    def update(self, new_data: pd.DataFrame) -> None:\n",
    "        \"\"\"Méthode abstraite pour mettre à jour les données.\"\"\"\n",
    "        raise NotImplementedError(\"La sous-classe doit implémenter la méthode abstraite\")\n",
    "\n",
    "# Centralisation des noms de tables\n",
    "class Tables:\n",
    "    CALC : str = config['connexion']['tables']['calc']\n",
    "    JOURS : str = config['connexion']['tables']['jours']\n",
    "    MOIS : str = config['connexion']['tables']['mois']\n",
    "    MAILLES : str = config['connexion']['tables']['mailles']\n",
    "\n",
    "class Maille(BaseTable):\n",
    "    \"\"\"Classe pour gérer les mailles (structures hiérarchiques).\"\"\"\n",
    "    def __init__(self, db_connection: DatabaseAccess, historization_error: HistorisationError):\n",
    "        self.historization_error = historization_error or HistorisationError()       \n",
    "        super().__init__(Tables.MAILLES, db_connection, self.historization_error)        \n",
    "        \n",
    "    def update(self, new_data: pd.DataFrame) -> None:\n",
    "        \"\"\"Met à jour les mailles avec de nouvelles données.\"\"\"\n",
    "        exitcode = 0\n",
    "        if not isinstance(new_data, pd.DataFrame) or new_data.empty:\n",
    "            logger_info.warning(\"Aucune nouvelle donnée à mettre à jour pour les mailles\")\n",
    "        try:\n",
    "            logger_info.info(\"Mise à jour des mailles\")\n",
    "            with manage_dataframe(self.get_data()) as df_mailles_existing:            \n",
    "                with manage_dataframe(new_data.drop_duplicates(subset=['maille'])) as new_data:\n",
    "                    new_mailles = new_data[~new_data['maille'].isin(df_mailles_existing['label'])]\n",
    "                    if not new_mailles.empty:\n",
    "                        self._insert_new_mailles(new_mailles, df_mailles_existing)\n",
    "                    else:\n",
    "                        logger_info.info(\"Aucune nouvelle maille à ajouter\")\n",
    "        except Exception as e:\n",
    "            error_msg =f\"Erreur lors de la mise à jour des mailles : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error(error_msg)\n",
    "\n",
    "    def _insert_new_mailles(self, new_mailles: pd.DataFrame, existing_mailles: pd.DataFrame) -> None:\n",
    "        try: \n",
    "            max_id = existing_mailles['id_maille'].max() if not existing_mailles.empty else 0\n",
    "            label_to_id = dict(zip(existing_mailles['label'], existing_mailles['id_maille']))\n",
    "            new_mailles_to_insert = []\n",
    "\n",
    "            def insert_maille(label: str, parent_label: Optional[str]) -> Dict[str, Union[int, str]]:\n",
    "                nonlocal max_id\n",
    "                if label in label_to_id:\n",
    "                    return  # La maille existe déjà\n",
    "                max_id += 1\n",
    "                parent_id = label_to_id.get(parent_label, 0)\n",
    "                new_maille = {\n",
    "                    'id_maille': max_id,\n",
    "                    'label': label,\n",
    "                    'id_parent': parent_id\n",
    "                }\n",
    "                new_mailles_to_insert.append(new_maille)\n",
    "                label_to_id[label] = max_id\n",
    "                return new_maille\n",
    "            # D'abord, insérer toutes les mailles parents\n",
    "            for _, row in new_mailles.iterrows():            \n",
    "                parent_label = row['maille_parent']\n",
    "                if parent_label and parent_label not in label_to_id:\n",
    "                    insert_maille(parent_label, None)\n",
    "                    logger_info.info(f\"Maille parent créée : {parent_label}\")\n",
    "            # Ensuite, insérer les mailles enfants\n",
    "            for _, row in new_mailles.iterrows():\n",
    "                label = row['maille']\n",
    "                parent_label = row['maille_parent']\n",
    "                insert_maille(label, parent_label)\n",
    "            if new_mailles_to_insert:            \n",
    "                df_to_insert = pd.DataFrame(new_mailles_to_insert)\n",
    "                self.db_connection.insert_dataframe(df_to_insert, self.table_name)\n",
    "                logger_info.info(f\"Ajout de {len(new_mailles_to_insert)} nouvelles mailles\")                \n",
    "        except Exception as e:           \n",
    "            error_msg =f\"Erreur lors de l'insertion de la maille : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "                        \n",
    "class Calc(BaseTable):\n",
    "    \"\"\"Classe pour gérer les calculs.\"\"\"\n",
    "    def __init__(self, db_connection: DatabaseAccess, maille: Maille, rapport: List[str], historization_error: HistorisationError):\n",
    "        self.historization_error = historization_error or HistorisationError()        \n",
    "        super().__init__(Tables.CALC, db_connection, self.historization_error)\n",
    "        self.rapport = rapport\n",
    "        self.maille = maille           \n",
    "\n",
    "    def update(self, new_calcs: pd.DataFrame) -> None:\n",
    "        \"\"\"Met à jour les calculs avec de nouvelles données.\"\"\"\n",
    "        if not isinstance(new_calcs, pd.DataFrame) or new_calcs.empty:\n",
    "            logger_info.warning(\"Aucune nouvelle donnée à mettre à jour pour les calculs\")\n",
    "        try:\n",
    "            logger_info.info(\"Mise à jour des calculs\")\n",
    "            with manage_dataframe(self.get_data()) as df_calcs_existing:\n",
    "                with manage_dataframe(new_calcs.drop_duplicates(subset=['indicateur'])) as new_calcs:\n",
    "                    new_calcs_to_add = new_calcs[~new_calcs['indicateur'].isin(df_calcs_existing['label'])]\n",
    "                    if not new_calcs_to_add.empty:\n",
    "                        self._insert_new_calcs(new_calcs_to_add, df_calcs_existing)\n",
    "                    else:\n",
    "                        logger_info.info(\"Aucun nouveau calcul à ajouter\")\n",
    "        except Exception as e:            \n",
    "            error_msg =f\"Erreur lors de la mise à jour des calculs : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error(error_msg) \n",
    "\n",
    "    def _insert_new_calcs(self, new_calcs: pd.DataFrame, existing_calcs: pd.DataFrame) -> None: \n",
    "        try: \n",
    "            max_id = existing_calcs['id_calc'].max() if not existing_calcs.empty else 0\n",
    "            calc_label_to_id = dict(zip(existing_calcs['label'], existing_calcs['id_calc']))\n",
    "            maille_label_to_id = dict(zip(self.maille.get_data()['label'], self.maille.get_data()['id_maille']))\n",
    "            new_calcs_to_insert = []\n",
    "            def insert_calc(indicateur: str, parent: Optional[str], maille: str) -> Dict[str, Union[int, str, List[str]]]:\n",
    "                nonlocal max_id\n",
    "                if indicateur in calc_label_to_id:\n",
    "                    return  # Le calcul existe déjà\n",
    "                max_id += 1\n",
    "                parent_id = calc_label_to_id.get(parent, 0)\n",
    "                id_maille_groupe = maille_label_to_id.get(maille, 0)\n",
    "                new_calc = {\n",
    "                    'id_calc': max_id,\n",
    "                    'label': indicateur,\n",
    "                    'id_parent': parent_id,\n",
    "                    'id_maille_groupe': id_maille_groupe,\n",
    "                    'rapports': self.rapport\n",
    "                }\n",
    "                new_calcs_to_insert.append(new_calc)\n",
    "                calc_label_to_id[indicateur] = max_id\n",
    "                return new_calc\n",
    "            # D'abord, insérer tous les calculs parents\n",
    "            for _, row in new_calcs.iterrows():            \n",
    "                parent_label = row['indicateur_parent']\n",
    "                if parent_label and parent_label not in calc_label_to_id:\n",
    "                    insert_calc(parent_label, None, row['maille_parent'])\n",
    "                    logger_info.info(f\"Calcul parent créé : {parent_label}\")\n",
    "            # Ensuite, insérer les calculs enfants\n",
    "            for _, row in new_calcs.iterrows():\n",
    "                label = row['indicateur']\n",
    "                parent_label = row['indicateur_parent']\n",
    "                maille_label = row['maille_parent']\n",
    "                insert_calc(label, parent_label, maille_label)\n",
    "            if new_calcs_to_insert:\n",
    "                df_to_insert = pd.DataFrame(new_calcs_to_insert)\n",
    "                self.db_connection.insert_dataframe(df_to_insert, self.table_name)\n",
    "                logger_info.info(f\"Ajout de {len(new_calcs_to_insert)} nouveaux calculs\")                \n",
    "        except Exception as e:\n",
    "            error_msg =f\"Erreur lors de l'insertion du calc : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error(error_msg) \n",
    "\n",
    "class Jour(BaseTable):\n",
    "    \"\"\"Classe pour gérer les données journalières.\"\"\"\n",
    "    def __init__(self, db_connection: DatabaseAccess, rapport: List[str], date: date, historization_error: HistorisationError, maille: Maille):\n",
    "        self.historization_error = historization_error or HistorisationError()\n",
    "        super().__init__(Tables.JOURS, db_connection, self.historization_error)        \n",
    "        self.rapport = rapport\n",
    "        self.maille = maille\n",
    "        self.date = date\n",
    "        \n",
    "    def update(self, new_data: pd.DataFrame) -> None:\n",
    "        \"\"\"Met à jour les calculs avec de nouvelles données.\"\"\"\n",
    "        if not isinstance(new_data, pd.DataFrame) or new_data.empty:\n",
    "            logger_info.warning(\"Aucune nouvelle donnée à mettre à jour pour les jours\")                    \n",
    "        try:\n",
    "            logger_info.info(\"Mise à jour des données journalières\")                       \n",
    "            with manage_dataframe(Calc(self.db_connection, self.maille, self.rapport,self.historization_error).get_data()) as calc_data:\n",
    "                with manage_dataframe(self.maille.get_data()) as maille_data:\n",
    "                    calc_data_unique = calc_data.drop_duplicates(subset='label', keep='first')\n",
    "                    maille_data_unique = maille_data.drop_duplicates(subset='label', keep='first')\n",
    "                    with manage_dataframe(new_data) as new_data:\n",
    "                        new_data = new_data.merge(calc_data_unique[['label', 'id_calc']], \n",
    "                                                  left_on='indicateur', \n",
    "                                                  right_on='label', \n",
    "                                                  how='left')\n",
    "                        new_data = new_data.merge(maille_data_unique[['label', 'id_maille']], \n",
    "                                                  left_on='maille', \n",
    "                                                  right_on='label', \n",
    "                                                  how='left')\n",
    "                        new_data['date'] = self.date                        \n",
    "                        to_insert = new_data[['id_calc', 'id_maille', 'date', 'valeur']].dropna()\n",
    "                        if not to_insert.empty:\n",
    "                            self.db_connection.insert_dataframe(to_insert, self.table_name)\n",
    "                            logger_info.info(f\"Insertion de {len(to_insert)} nouvelles lignes dans la table des jours\")\n",
    "                        else:\n",
    "                            logger_info.warning(\"Aucune nouvelle donnée valide à insérer dans la table des jours\")   \n",
    "        except Exception as e:            \n",
    "            error_msg =f\"Erreur lors de la mise à jour des données journalières : {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            self.historization_error.add_error(error_msg)\n",
    "            logger_info.error(f\"HistorisationError après ajout : {self.historization_error.get_str()}\")\n",
    "\n",
    "class Mois(BaseTable):\n",
    "    \"\"\"Classe pour gérer les données mensuelles.\"\"\"\n",
    "    def __init__(self, db_connection: DatabaseAccess, rapport_dir: Path, historization_error: HistorisationError):\n",
    "        self.historization_error = historization_error or HistorisationError()\n",
    "        super().__init__(Tables.MOIS, db_connection, self.historization_error)\n",
    "        self.rapport_dir = rapport_dir       \n",
    "        \n",
    "    def update(self) -> None:   \n",
    "        \"\"\"Met à jour les calculs avec de nouvelles données.\"\"\"\n",
    "        if not hasattr(self, 'historization_error'):\n",
    "            print(\"historization_error n'existe pas\")\n",
    "        try:\n",
    "            # Vérifier si le fichier indic_mois_kpi.sql existe\n",
    "            sql_file = os.path.join(self.rapport_dir, SQL_MOIS)            \n",
    "            if os.path.exists(sql_file):\n",
    "                # Si le fichier existe, exécuter le script SQL\n",
    "                df_mois = self.db_connection.read_sql_query_file(sql_file)                \n",
    "            else:\n",
    "                rapport = [os.path.basename(self.rapport_dir).upper()]\n",
    "                # Sinon, utiliser la requête SQL fournie\n",
    "                query = f\"\"\"\n",
    "                SELECT id_calc, id_maille, \n",
    "                       date_trunc('month', (current_date - interval '1 month'))::date as \"date\", \n",
    "                       avg(valeur) as valeur \n",
    "                FROM {self.schema}.{Tables.JOURS} j \n",
    "                JOIN {self.schema}.{Tables.CALC} c USING(id_calc) \n",
    "                WHERE extract(month from \"date\") = extract(month from current_date - interval '1 month') \n",
    "                  AND c.rapports @> array[{rapport}]\n",
    "                GROUP BY id_calc, id_maille, \n",
    "                         date_trunc('month', (current_date - interval '1 month'))::date\n",
    "                \"\"\"\n",
    "                df_mois = self.db_connection.read_sql_query(query)\n",
    "            if not df_mois.empty:\n",
    "                self.db_connection.insert_dataframe(df_mois, self.table_name, if_exists='append')\n",
    "                logger_info.info(f\"Added {len(df_mois)} monthly records\")                \n",
    "            else:\n",
    "                logger_info.warning(\"Pas de données mensuelles à historiser\")            \n",
    "        except Exception as e:            \n",
    "            error_msg =f\"Erreur lors de l'histiorisation des données mensuelles: {str(e)}\"\n",
    "            logger_info.error(error_msg)                        \n",
    "            raise self.historization_error.add_error(error_msg)\n",
    "            \n",
    "@log_execution_time\n",
    "class Rapport:\n",
    "    def __init__(self, rapport_dir: Path, db_connection: DatabaseAccess, historization_error: HistorisationError, flag_manager: Optional[FlagManager] = None, date: Optional[date] = None):\n",
    "        self.historization_error = historization_error\n",
    "        self.db_connection = db_connection\n",
    "        self.date = date or datetime.now().date()\n",
    "        self.rapport_dir = Path(rapport_dir)\n",
    "        self.rapport = [self.rapport_dir.name.upper()]\n",
    "        self.maille = Maille(self.db_connection, self.historization_error)\n",
    "        self.calc = Calc(self.db_connection, self.maille, self.rapport, self.historization_error)\n",
    "        self.jour = Jour(self.db_connection, self.rapport, self.date, self.historization_error, self.maille)\n",
    "        self.mois = Mois(self.db_connection, rapport_dir, self.historization_error)\n",
    "        self.flag_manager = flag_manager\n",
    "        self.exitcode = 0\n",
    "        self.sql_processor = SQLFileProcessor(self.db_connection, self.historization_error)        \n",
    "\n",
    "    def process_sql_files(self) -> int:\n",
    "        try:\n",
    "            self._process_daily_files()\n",
    "            self._process_monthly_file()\n",
    "            return self.exitcode\n",
    "        except Exception as e:\n",
    "            self._handle_error(f\"Erreur lors du traitement processus des fichiers SQL : {str(e)}\")\n",
    "            return self.exitcode\n",
    "\n",
    "    def _process_daily_files(self):\n",
    "        for sql_file in self.rapport_dir.glob('*.sql'):\n",
    "            if SQL_MOIS not in sql_file.name:\n",
    "                self._process_single_file(sql_file)\n",
    "\n",
    "    def _process_monthly_file(self):\n",
    "        monthly_file = self.rapport_dir / SQL_MOIS\n",
    "        if monthly_file.exists():\n",
    "            self._process_single_file(monthly_file, is_monthly=True)\n",
    "        elif not self.flag_manager.manage_flag(FLAG_FILE_MONTHLY, FlagAction.CHECK, FlagType.MONTHLY):\n",
    "            self._update_monthly_data()\n",
    "\n",
    "    def _process_single_file(self, sql_file: Path, is_monthly: bool = False):\n",
    "        if not self._should_process_file(sql_file, is_monthly):\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            data = self.sql_processor.process_file(sql_file)\n",
    "            if data is not None and not data.empty:\n",
    "                self._update_data(data, is_monthly)                \n",
    "                self.flag_manager.manage_flag(sql_file, FlagAction.CREATE, FlagType.MONTHLY if is_monthly else FlagType.DAILY)\n",
    "            else:\n",
    "                logger_info.warning(f\"Le fichier {sql_file} n'a pas retourné de DataFrame valide ou est vide.\")\n",
    "        except Exception as e:\n",
    "            self._handle_error(f\"Erreur lors du traitement du fichier {sql_file}: {str(e)}\")\n",
    "\n",
    "    def _should_process_file(self, sql_file: Path, is_monthly: bool) -> bool:\n",
    "        flag_type = FlagType.MONTHLY if is_monthly else FlagType.DAILY\n",
    "        if self.flag_manager.manage_flag(sql_file, FlagAction.CHECK, flag_type):\n",
    "            logger_info.warning(f\"Le fichier {sql_file.name} a déjà été traité.\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def _update_data(self, data: pd.DataFrame, is_monthly: bool):\n",
    "        if is_monthly:\n",
    "            self.mois.update()\n",
    "        else:\n",
    "            self.maille.update(data[['maille', 'maille_parent']])\n",
    "            self.calc.update(data[['indicateur', 'indicateur_parent', 'maille_parent']])\n",
    "            self.jour.update(data)\n",
    "            \n",
    "    def _update_monthly_data(self):\n",
    "        self.mois.update()\n",
    "        self.flag_manager.manage_flag(FLAG_FILE_MONTHLY, FlagAction.CREATE, FlagType.MONTHLY)\n",
    "\n",
    "    def _handle_error(self, error_msg: str):\n",
    "        logger_info.error(error_msg)\n",
    "        self.historization_error.add_error(error_msg)\n",
    "        self.exitcode += 1   \n",
    "\n",
    "class SQLFileProcessor:\n",
    "    def __init__(self, db_connection: DatabaseAccess, historization_error: HistorisationError):\n",
    "        self.db_connection = db_connection\n",
    "        self.historization_error = historization_error\n",
    "\n",
    "    def process_file(self, sql_file: Path) -> Optional[pd.DataFrame]:\n",
    "        try:\n",
    "            data = self.db_connection.read_sql_query_file(sql_file)\n",
    "            if set(SQL_FORMAT_LABELS).issubset(data.columns):\n",
    "                return data\n",
    "            else:               \n",
    "                error_msg = f\"Colonnes manquantes dans le fichier {sql_file}: {str(e)}\"\n",
    "                logger_info.error(error_msg)\n",
    "                self.historization_error.add_error(error_msg)    \n",
    "        except Exception as e:           \n",
    "            error_msg = f\"Erreur lors du traitement {sql_file}: {str(e)}\"\n",
    "            logger_info.error(error_msg)\n",
    "            self.historization_error.add_error(error_msg)\n",
    "            \n",
    "class Traitement:\n",
    "    def __init__(self, db_connection: DatabaseAccess, historization_error: HistorisationError, flag_manager: FlagManager):\n",
    "        self.db_connection = db_connection\n",
    "        self.historization_error = historization_error\n",
    "        self.flag_manager = flag_manager\n",
    "        self.data_cleaner = DataCleaner(self.db_connection, self.historization_error)\n",
    "\n",
    "    def process_action(self, action: str, date: Optional[date] = None, rapport_dir: Optional[Path] = None) -> int:\n",
    "        try:\n",
    "            logger_info.info(f\"Process_data, action souhaitée : {action}\")\n",
    "            \n",
    "            is_monthly = action == 'mois'\n",
    "            self._clean_old_data(is_monthly)\n",
    "            \n",
    "            if action == 'default':\n",
    "                return self._process_default(date)\n",
    "            elif action == 'jour':\n",
    "                return self._process_jour(date)\n",
    "            elif action == 'mois':\n",
    "                return self._process_mois()\n",
    "            elif action == 'rapport' and rapport_dir:\n",
    "                return self._process_rapport(rapport_dir)\n",
    "            else:\n",
    "                error_msg = f\"Action non reconnue : {action}\"\n",
    "                raise ValueError(error_msg)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Erreur lors du traitement {action} : {str(e)}\"\n",
    "            logger_info.error(error_msg)\n",
    "            self.historization_error.add_error(error_msg)\n",
    "            return 1\n",
    "\n",
    "    def _process_default(self, date: Optional[date] = None) -> int:\n",
    "        logger_info.info(\"traitement par default\")\n",
    "        if not self.flag_manager.manage_flag(FLAG_FILE_DAILY, FlagAction.CHECK) or date:\n",
    "            exitcode = 0\n",
    "            for rapport_dir in SQLPATH.glob('*'):\n",
    "                if rapport_dir.is_dir():\n",
    "                    rapport = Rapport(Path(rapport_dir), self.db_connection, self.historization_error, self.flag_manager, date)\n",
    "                    exitcode += rapport.process_sql_files()\n",
    "            if not date:\n",
    "                self.flag_manager.manage_flag(FLAG_FILE_DAILY, FlagAction.CREATE)\n",
    "            return exitcode\n",
    "        return 0\n",
    "\n",
    "    def _process_jour(self, date: Optional[date] = None) -> int:\n",
    "        date = date if date else datetime.now().date()\n",
    "        self.db_connection.delete_day_data(date)\n",
    "        self.flag_manager.manage_flag(FLAG_FILE_DAILY, FlagAction.REMOVE)\n",
    "        return self._process_default(date)\n",
    "\n",
    "    def _process_mois(self) -> int:\n",
    "        last_month = (date.today().replace(day=1) - timedelta(days=1)).replace(day=1)\n",
    "        self.db_connection.delete_month_data(last_month.year, last_month.month)\n",
    "        self.flag_manager.manage_flag(FLAG_FILE_MONTHLY, FlagAction.REMOVE)\n",
    "        self._clean_old_data(true)\n",
    "        exitcode = 0\n",
    "        for rapport_dir in SQLPATH.glob('*'):\n",
    "            if rapport_dir.is_dir():\n",
    "                exitcode += Mois(self.db_connection, str(rapport_dir), self.historization_error).update()\n",
    "        self.flag_manager.manage_flag(FLAG_FILE_MONTHLY, FlagAction.CREATE, FlagType.MONTHLY)\n",
    "        return exitcode\n",
    "\n",
    "    def _process_rapport(self, rapport_dir: Path) -> int:\n",
    "        rapport = Rapport(rapport_dir, self.db_connection, self.historization_error, self.flag_manager)\n",
    "        return rapport.process_sql_files()  \n",
    "    \n",
    "    def _clean_old_data(self, is_monthly: Optional[bool] = False):\n",
    "        if is_monthly:\n",
    "            self.data_cleaner.clean_monthly_data()\n",
    "        else:\n",
    "            self.data_cleaner.clean_daily_data()\n",
    "\n",
    "    \n",
    "    \n",
    "class DataCleaner:\n",
    "    def __init__(self, db_connection: DatabaseAccess, historization_error: HistorisationError):\n",
    "        self.db_connection = db_connection\n",
    "        self.historization_error = historization_error\n",
    "\n",
    "    def clean_daily_data(self):\n",
    "        self._clean_data(SCHEMA, Tables.JOURS, config['data_cleanup']['daily_retention_months'])\n",
    "\n",
    "    def clean_monthly_data(self):\n",
    "        self._clean_data(SCHEMA, Tables.MOIS,config['data_cleanup']['monthly_retention_months'])\n",
    "\n",
    "    def _clean_data(self, schema: str, table: str, interval: str):\n",
    "        try:\n",
    "            query = f\"\"\"\n",
    "            DELETE FROM {schema}.{table}\n",
    "            WHERE date < CURRENT_DATE - INTERVAL '{interval}'\n",
    "            \"\"\"\n",
    "            result = self.db_connection.execute_query(query)\n",
    "            affected_rows = result.rowcount if hasattr(result, 'rowcount') else 0\n",
    "            logger_info.info(f\"Suppression de {affected_rows} lignes de données de {table}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Erreur lors du nettoyage des données de {table} : {str(e)}\")  \n",
    "    \n",
    "def parse_arguments() -> Optional[argparse.Namespace]:\n",
    "    \"\"\"Parse les arguments de ligne de commande ou retourne None si exécuté dans Jupyter.\"\"\"\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        # Exécution dans Jupyter, pas de parsing d'arguments\n",
    "        return None\n",
    "    else:\n",
    "        # Exécution comme script autonome, parser les arguments\n",
    "        parser = argparse.ArgumentParser(description=\"Traitement des données journalières et mensuelles\")\n",
    "        parser.add_argument('--jour', action='store_true', help=\"Force le recalcul des données journalières\")\n",
    "        parser.add_argument('--mois', action='store_true', help=\"Force le recalcul des données mensuelles\")\n",
    "        parser.add_argument('--veille', action='store_true', help=\"Force le recalcul des données de la veille\")\n",
    "        parser.add_argument('--sup', action='store_true', help=\"Force la suppression des données journalières\")\n",
    "        parser.add_argument('--rapport', type=Path, help=\"Chemin vers le répertoire du rapport\")\n",
    "        parser.add_argument('--user', help=\"Nom d'utilisateur pour la connexion à la base de données\")\n",
    "        parser.add_argument('--password', help=\"Mot de passe pour la connexion à la base de données\")\n",
    "        parser.add_argument('--host', help=\"Hôte de la base de données\")\n",
    "        parser.add_argument('--port', type=int, help=\"Port de la base de données\")\n",
    "        parser.add_argument('--bdd', help=\"Nom de la base de données\")\n",
    "        return parser.parse_args()  \n",
    "\n",
    "# Fonction principale    \n",
    "@log_execution_time\n",
    "def main() -> int:\n",
    "    db_connection = None\n",
    "    error_handler = HistorisationError()\n",
    "    flag_manager = FlagManager(error_handler)\n",
    "    try:\n",
    "        args = parse_arguments()\n",
    "        config = charger_config('config.json')\n",
    "        \n",
    "        connection_params = {\n",
    "            'user': getattr(args, 'user', None) or config['connexion']['user'],\n",
    "            'password': getattr(args, 'password', None) or config['connexion']['password'],\n",
    "            'host': getattr(args, 'host', None) or config['connexion']['host'],\n",
    "            'port': getattr(args, 'port', None) or config['connexion']['port'],\n",
    "            'bdd': getattr(args, 'bdd', None) or config['connexion']['bdd']\n",
    "        }\n",
    "        \n",
    "        db_connection = DatabaseAccess(error_handler, **connection_params)\n",
    "        traitement = Traitement(db_connection, error_handler, flag_manager)\n",
    "        actions = {\n",
    "            \n",
    "            'jour': lambda: traitement.process_action('jour'),\n",
    "            'mois': lambda: traitement.process_action('mois'),\n",
    "            'veille': lambda: traitement.process_action('jour', (datetime.now() - timedelta(days=1)).date()),\n",
    "            'rapport': lambda: traitement.process_action( 'rapport', rapport_dir=Path(args.rapport)) if args.rapport else 0\n",
    "        }        \n",
    "        if args is None or not any(getattr(args, action, False) for action in actions):  \n",
    "            logger_info.info('Actualisation manuelle du rapport R039')\n",
    "            traitement.process_action('default')\n",
    "            #process_data(db_connection, error_handler,flag_manager, 'default',rapport_dir=Path(\"sql/r039\"))             \n",
    "        else:\n",
    "            for action, func in actions.items():\n",
    "                if getattr(args, action, False):                   \n",
    "                    func()  \n",
    "        \n",
    "        if args is None or not any(getattr(args, action, False) for action in ['jour', 'mois', 'veille', 'rapport']):\n",
    "            logger_info.info('Actualisation manuelle des rapports')\n",
    "            exitcode = traitement.process_action('default')\n",
    "        else:\n",
    "            exitcode = 0\n",
    "            if args.jour:\n",
    "                exitcode += traitement.process_action('jour')\n",
    "            if args.mois:\n",
    "                exitcode += traitement.process_action('mois')\n",
    "            if args.veille:\n",
    "                exitcode += traitement.process_action('jour', date=(datetime.now() - timedelta(days=1)).date())\n",
    "            if args.rapport:\n",
    "                exitcode += traitement.process_action('rapport', rapport_dir=Path(args.rapport))\n",
    "        \n",
    "        return exitcode, error_handler.get_summary()\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Erreur générale : {str(e)}\"\n",
    "        logger_info.error(error_msg)\n",
    "        error_handler.add_error(error_msg)\n",
    "        return 1, error_handler.get_summary()\n",
    "\n",
    "    finally:\n",
    "        if db_connection:\n",
    "            try:\n",
    "                db_connection.disconnect()\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Erreur lors de la déconnexion : {str(e)}\"\n",
    "                logger_info.error(error_msg)\n",
    "                error_handler.add_error(error_msg)\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exitcode, (messages, _) = main()\n",
    "    if exitcode > 0:\n",
    "        print(messages)\n",
    "    sys.exit(exitcode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
